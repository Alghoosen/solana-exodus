# Long term RPC Transaction History
There's a need for RPC to serve at least 6 months of transaction history.  The
current history, on the order of days, is insufficient for downstream users.

6 months of transaction data cannot be stored practically in a validator's
rocksdb ledger so an external data store is necessary.   The validator's
rocksdb ledger will continue to serve as the primary data source, and then will
fall back to the external data store.

The affected RPC endpoints are:
* [getFirstAvailableBlock](https://docs.solana.com/apps/jsonrpc-api#getfirstavailableblock)
* [getConfirmedBlock](https://docs.solana.com/apps/jsonrpc-api#getconfirmedblock)
* [getConfirmedBlocks](https://docs.solana.com/apps/jsonrpc-api#getconfirmedblocks)
* [getConfirmedSignaturesForAddress](https://docs.solana.com/apps/jsonrpc-api#getconfirmedsignaturesforaddress)
* [getConfirmedTransaction](https://docs.solana.com/apps/jsonrpc-api#getconfirmedtransaction)
* [getSignatureStatuses](https://docs.solana.com/apps/jsonrpc-api#getsignaturestatuses)

Note that [getBlockTime](https://docs.solana.com/apps/jsonrpc-api#getblocktime)
is not supported, as once https://github.com/solana-labs/solana/issues/10089 is
fixed then `getBlockTime` will be removed.

Some system design constraints:
* The volume of data to store and search can quickly jump into the terabytes,
  and is immutable.
* The system should be as light as possible for SREs.  For example an SQL
  database cluster that requires an SRE to continually monitor and rebalance
  nodes is undesirable.
* Data must be searchable in real time - batched queries that take minutes or
  hours to run are unacceptable.
* Easy to replicate the data worldwide to co-locate it with the RPC endpoints
  that will utilize it.
* Interfacing with the external data store should be easy and not require
  depending on risky lightly-used community-supported code libraries

These constraints imply a cloud-provider hosted database or storage solution of
some sort.  A survey of the current out-of-the-box GCP and AWS offerings didn't
produce an exact fit, each didn't seem to align with one or more of the above
design constraints.

Therefore a purpose-built data store is proposed that uses the primitive storage
bucket functionality supported by most cloud providers.  While limited in
features bucket storage is very widely used with well documented performance
characteristics and pitfalls.

## Bucket Schema
A single cloud storage bucket is used to hold all transaction data.

New data may be copied into the bucket at anytime without affecting the existing
data, and all data is immutable.  Generally the expectation is that new data
will be uploaded once an current epoch completes but there is no limitation on
the frequency of data dumps.

Cleanup of old data is automatic by configuring the data retention policy of the
bucket appropriately, it just disappears.  Therefore the order of when data is
added becomes important.  For example if data from epoch N-1 is added after data
from epoch N, the older epoch data will outlive the newer data.  However beyond
producing _holes_ in query results, this kind of unordered deletion will
have no ill effect.  Note that this method of cleanup effectively allows for an
unlimited amount of transaction data to be stored, restricted only by the
monetary costs of doing so.

The bucket schema supports the existing RPC endpoints only.  New RPC endpoints
in the future may require additions to the schema and potentially iterating over
all transactions to build up the necessary metadata.

Notable bucket storage features and constraints that influenced the schema are:
* always minimize the need to list objects, as `list` is a much more expensive
  operation than `get`
* only 1,000 objects may be listed before pagination occurs
* object listing will always be in lexical order

## Accessing Bucket Data
The bucket will be accessed using the [rust-s3](https://crates.io/crates/rust-s3) crate.
Unfortunately the Google Cloud Storage S3 API support is limited, and `rust-s3`
does not work with it, so the ledger will be stored natively in AWS S3 instead.
No usable Google Cloud Storage API crates appear to be available at this time.

## Bucket Population
The ongoing population of bucket data will occur on an epoch cadence through the
use of a new `solana-ledger-tool` command that will convert rocksdb data for a
given slot range into the bucket schema.

The same process will be run once, manually, to backfill the existing ledger
data.

### Block Information: `block/`
`block/<slot-id>` - gzipped block data

*slot-id* is generated by taking the 16 digit lower case hexadecimal
representation of the slot.  eg,
the *slot-id* for slot 42 would be 000000000000002a

The block data will the bincode version of
solana_transaction_status::ConfirmedBlock, so it's easily consumable by RPC, and
compressed to reduce object size

Note the object names have been designed to ensure that the oldest slot with a
confirmed block will always be first when the bucket objects prefixed by
`block/` are listed.

Object size: variable depending on the size of the block

### Block Map: `block-map/`
`block-map/<slot / 500_000>` - A bitmap representing the slots that contain a
confirmed block in the range `slot / 500_000 .. (slot + 1) / 500_000`.

Object size: ~61 kilobytes

NOTE: `block-map` will not need to be implemented in the first iteration.  The
same confirmed block information can be obtained by listing objects with the `block/` prefix.
`block-map` can be added later if Object listing API usage needs to be reduced.

### Account Address Transaction Signature Lookup: `tx-by-addr/`
`tx-by-addr/<base58 address>/<slot-id-one's-compliment-hex-slot-0-prefixed-to-16-digits>`

*slot-id* is generated by taking the 16 digit lower case hexadecimal
representation of the slot's ones compliment.
 eg, the *slot-id* for slot 42 would be ffffffffffffffd5

A binary list of transaction signatures that affect the given address in that
slot, with the transaction status and slot index for each.

Since it's more useful to be able to quickly find the newest transaction that
affects an address than the oldest, the object names have been designed to
ensure that the newest slot with transactions that affect an address will always
be first when the bucket objects prefixed by `tx-by-addr/<base58 address>/` are
listed.

Sysvar addresses are not indexed.  However frequently used programs such as
Vote or System will likely have an object for every confirmed slot.

Object size: ~77 bytes * number of affected transactions in the slot

### Transaction Signature Lookup: `tx/`
`tx/<base58-transaction-signature>` - Maps a transaction signature to its confirmed block, and index within that block.

Each object is formatted as:
* slot that contains the block with this transaction: u64
* transaction index within the block: u32
* transaction status: Option<TransactionError>

Object size: ~13 bytes

## Supported RPC endpoints
The following RPC endpoints will utilize the bucket data as a fallback for when
data is not available in a validator's local rocksdb ledger database.

### [getFirstAvailableBlock](https://docs.solana.com/apps/jsonrpc-api#getfirstavailableblock)
List objects under the `block/` prefix.  The name of the first object will be
the slot with the first available block

### [getConfirmedBlock](https://docs.solana.com/apps/jsonrpc-api#getconfirmedblock)
Get the `block/<hex-slot-0-prefixed-to-16-digits>` object, decompress it, and return it to the user

### [getConfirmedBlocks](https://docs.solana.com/apps/jsonrpc-api#getconfirmedblocks)

Before `block-map/` is implemented:
```rust,ignore
List objects under `block/` begining at start_slot until reaching end_slot.  For
500,000 slots, this will require 500 Object list API calls
```

If/when `block-map/` is implemented:
```rust,ignore
M=500_000
for `slot_div_M` in `start_slot / M` .. `end_slot / M`:
  Read the `block-map/<slot_div_M>` object and convert the contents from a bitmask
  to a list of slots (`bv:BitVec` should help)
```

### [getConfirmedSignaturesForAddress](https://docs.solana.com/apps/jsonrpc-api#getconfirmedsignaturesforaddress)
If a starting signature address is provided, read the the file
`tx/<base58-transaction-signature>` to figure its corresponding `slot` and
transaction index within that slot.  Otherwise use the latest confirmed slot.

List the next set of objects under under `tx-by-addr/<base58 address>` from the
starting slot.  For each slot object name, read the file and add the contained
list of signatures to the returned list until reaching the requested signature
limit.

### [getConfirmedTransaction](https://docs.solana.com/apps/jsonrpc-api#getconfirmedtransaction)
1. With the user-provided transaction signature, read the
the file `tx/<base58-transaction-signature>` to figure its location in the `block/`
objects.
2. Load the corresponding `block/` object file, seek to the transaction offset and
read the transaction

### [getSignatureStatuses](https://docs.solana.com/apps/jsonrpc-api#getsignaturestatuses)
For each user-provided transaction signature:
* perform the same logic as `getConfirmedTransaction` to lookup the transaction
  details, then fill out the RPC response object

## Storage Size/Cost Estimates
Assume:
* 200 validators submitting a vote transaction in each slot
* 432,000 slots per epoch, and 39,312,000 slots in 6 months at 2.5 slots/second
* Each system transfer transaction will have three accounts (to, from, system program id).
* Each vote transaction will have three non-sysvar accounts (vote account, vote authority, vote program id).
* block-map/ will use ~5.5 MB in 6 months (91 epochs), not worth considering further

### Sustained 1k TPS
Assume:
* 400 system transfers in each slot with unique to/from pairs (~1k TPS)

Each slot will produce the following objects, size: 0.45 MB:
* 1 `block/` object, size:  0.3 MB (estimate of 500 bytes per transaction)
* 600 `tx` objects, size: 0.008 MB
* 1202 `tx-by-addr` objects:
         * 1 for vote program, size: 0.015 MB
         * 1 for system program, size: 0.030 MB
         * 1200 for other addresses, size: 0.092 MB

At 0.45 MB per slot:
* 1.1 MB per second
* 194 GB per epoch
8 17.8 TB per 6 months

Cost:
* standard storage at $0.026 per GB per Month: $464 per month
* network egress and bucket operations are not calculated, depends on RPC usage.

### Sustained 50k TPS
Assume:
* 20,000 system transfers in each slot with unique to/from pairs (~50k TPS)

Each slot will produce the following objects, size: 14.9 MB:
* 1 `block/` object, size: 10 MB (estimate of 500 bytes per transaction)
* 20200 `tx` objects, size: 0.26 MB
* 40202 `tx-by-addr` objects:
         * 1 for vote program, size: 0.015 MB
         * 1 for system program, size: 1.54 MB
         * 40200 for other addresses, size: 3.1 MB

At 14.9 MB per slot:
* 37.2 MB per second
* 6.4 TB per epoch
* 588.8 TB per 6 months

Cost:
* standard storage at $0.026 per GB per Month: $15,309 per month
* network egress and bucket operations are not calculated, depends on RPC usage.
