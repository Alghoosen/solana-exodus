Long-term storage
---

We are building a decentralized storage network for a multi petabyte ledger.
But because of how flexible our smart contracts engine is, we can also use that
same storage network as virtualized disk space for contracts.

Our contracts are able to schedule asynchronous and eventually guaranteed
transactions on the network that we are calling Signals. The runtime also
guarantees that all the state of the contract has been generated by only the
contract code, and that all user inputs are recorded on chain. 

What that means is that all resident contract state can be recreated by running
the ledger. Storing this state in DDR is the most expensive part of the
runtime. Memory is significantly more expensive then storage, and cannot be
easily striped and distributed, since we need fast random access. So contracts
that need long term storage of large state we are offering the following
operations

```rust
 /// move the resident state memory into the ledger
store(page_address: PublicKey);

/// restore the resident state memory from the ledger
load(page_address: PublicKey);
```

Contracts can create a Signal which will move the memory that belongs to the
PublicKey into the ledger, thus reducing its costs. Then can later call a load
to bring that memory back.

How does it actually work in a permissionless network?

Store is fairly simple. The memory is simply sent as userdata over a
transaction and gets put into PoH. The PublicKey then simply stores the
location on “ledger” of where the memory is resident.

Load is much more complicated. Since nodes are not required to keep a full copy
of the ledger, each node only maintains a randomly selected stipe. To do a
load, each verifier has to retrieve the state from the network, and then agree
that the loaded state is correct. Because this operation is slow, we can’t make
it synchronous with respect to all other operations on chain, especially
finality. So this operation is broken up into several asynchronous steps that
eventually complete.

load transaction is signaled each verifier fetches the data each verifier
computes the hash of the loaded data when the super majority of the verifiers
have agreed on the hash, the memory is committed to the virtual machine state
the verification signature of the next virtual machine state reflects the
change Many rounds of finality could occur between step 1 and step 4.

Forgetting the data form the ledger The data the contract wrote to the ledger
can be recomputed from the ledger itself. So this piece of data can actually be
forgotten after the load operation completes.

For us that means that when the next round of ledger slices is selected, the
replicator nodes do not have to store the data bytes that were loaded into
resident memory. They can actually be removed from replication. What we do
keep, is the hash of those bytes that was mixed into Proof of History. So the
integrity of the clock remains.

PoH Count  | PoH      | Data Offset| Data Hash
-----------|----------|------------|----------
1000000    | 0x23a..  | 23423288   | 0x023f..
2000000    | 0x3fc..  | 23488888   | 0xf2d2..

If the data at PoH count 1,000,000 is memory thats loaded into the virtual
machine, 65,600 bytes at offset 23,423,288 to offset 23,488,888 can be removed from
replication. So next round of replication can skip storing this data. 
